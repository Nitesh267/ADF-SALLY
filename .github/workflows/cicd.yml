name: Deploy Azure Data Factory

on:
  push:
    branches:
      - ADF
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    env:
      AZURE_RESOURCE_GROUP: cw-mobile-rg
      AZURE_DATA_FACTORY_NAME: sally-tie-out-reporting-poc

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    # - name: Set up Azure CLI
    #   uses: azure/login@v1
    #   with:
    #     creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Install Azure CLI
      run: |
        curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash


    - name: Authenticate with Azure
      run: |
        az login --service-principal -u f07fbbe2-9424-46af-a574-a254e78cec71 -p 6hS8Q~W9TAtIvDl~exiQGSEhgkbpYfbsKRPT5bJq --tenant 0ed45c0a-a9b9-45ca-92b3-6cceb454c222
        # az login --service-principal -u ${{ secrets.AZURE_CLIENT_ID }} -p ${{ secrets.AZURE_CLIENT_SECRET }} --tenant ${{ secrets.AZURE_TENANT_ID }}
      env:
        AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
        AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
        AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

    - name: Set Azure subscription
      run: az account set --subscription 0eb16af5-8c5c-42f6-85cb-65f4f74714ce
    # Install az extension for Data Factory (if not already installed)
    - name: Install az extension for Data Factory (optional)
      run: |
        az extension add --name datafactory --only-show-errors

        
    
    - name: Loop through Linked Service JSON files
      run: |
        for filename in ./linkedService/*.json; do
          linked_service_name="${filename##*/}"
          linked_service_name="${linked_service_name%.*}"  # Extract name from filename
          
          # Extract properties part from linked service JSON content
          linked_service_properties=$(jq -c '.properties' "$filename")

          echo "Deploying linked service $linked_service_name from $filename"

          # Create linked service using az command
          az datafactory linked-service create \
            --factory-name "sally-tie-out-reporting-poc" \
            --resource-group "cw-mobile-rg" \
              --linked-service-name "$linked_service_name" \
              --properties "$linked_service_properties" \
              --verbose

          echo "Created linked service: $linked_service_name"
        done
 
    # - name: Deploy Data Factory Datasets
    #   run: |
    #       for filename in ./dataset/*.json; do
    #         dataset_name="${filename##*/}"
    #         dataset_name="${dataset_name%.*}"  # Extract name from filename
      
    #         # Read dataset JSON content and format it as a JSON string
    #         dataset_properties=$(jq -c '.properties' "$filename")
            
    #         # Check if dataset definition is empty
    #         if [[ -z "$dataset_properties" ]]; then
    #           echo "Error: Empty dataset definition in file: $filename"
    #           continue  # Skip to the next iteration
    #         fi
      
    #         echo "Deploying dataset $dataset_name from $filename"
      
    #         # Create dataset using az command
    #         az datafactory dataset create \
    #             --factory-name "sally-tie-out-reporting-poc" \
    #             --resource-group "cw-mobile-rg" \
    #             --name "$dataset_name" \
    #             --properties "$dataset_properties" \
    #             --verbose
      
    #         echo "Created dataset: $dataset_name"
    #       done
          
    #       env:
    #         AZURE_RESOURCE_GROUP: cw-mobile-rg
    #         AZURE_DATA_FACTORY_NAME: sally-tie-out-reporting-poc
      
    - name: Create datasets from JSON files in dataset folder
      run: |
        #!/bin/bash
    
        # Define the dataset folder path
        dataset_dir="./dataset/"
    
        # Loop through all JSON files in the directory
        for filename in "$dataset_dir"*.json; do
          # Extract dataset name from filename (assuming filename format matches dataset name)
          dataset_name="${filename##*/}"
          dataset_name="${dataset_name%.*}"  # Remove extension
    
          # Read the dataset JSON content from the file
          dataset_json=$(<"$filename")
    
          # Use az datafactory dataset create with the file content
          az datafactory dataset create \
            --properties "$dataset_json" \
            --factory-name "sally-tie-out-reporting-poc" \
            --resource-group "cw-mobile-rg" \
            --name "$dataset_name"
    
          echo "Created dataset: $dataset_name"
        done
    
        echo "Finished processing dataset JSON files."
    
    
    - name: Run dataflow creation script
      run: |
        #!/bin/bash

        # Define the directory containing dataflow JSON files
        dataflow_dir="./dataflow/"

        # Loop through all JSON files in the directory
        for filename in "$dataflow_dir"*.json; do
            # Extract dataflow name from filename (assuming filename format matches dataflow name)
            dataflow_name="${filename##*/}"
            dataflow_name="${dataflow_name%.*}"  # Remove extension

            # Construct the az datafactory command
            az datafactory data-flow create \
            -g cw-mobile-rg \
            -f sally-tie-out-reporting-poc \
            -n "$dataflow_name" \
            -t "Flowlet" \
            --properties "$filename"

            echo "Created dataflow: $dataflow_name"
        done

        echo "Finished processing dataflow JSON files."
    - name: Loop through pipeline JSON files
      run: |  # Loop through JSON files
        for filename in ./pipeline/*.json; do
            pipeline_name="${filename##*/}"
            pipeline_name="${pipeline_name%.*}"  # Extract name from filename

            # Read pipeline JSON content
            pipeline_json=$(cat "$filename")

            # Create ADF pipeline using az command with definition as argument
            az datafactory pipeline create \
            --factory-name "sally-tie-out-reporting-poc" \
            --resource-group "cw-mobile-rg" \
            --name "$pipeline_name" \
            --pipeline "$pipeline_json"

            echo "Created pipeline: $pipeline_name"
        done

    
# Loop through trigger JSON files
    # - name: Loop through Trigger JSON files
    #   run: |
    #     for filename in ./trigger/*.json; do
    #       trigger_name="${filename##*/}"
    #       trigger_name="${trigger_name%.*}"  # Extract name from filename

    #       # Read trigger JSON content and format it as a JSON string
    #       trigger_properties=$(jq -c '.properties' "$filename")
          
    #       # Check if trigger definition is empty
    #       if [[ -z "$trigger_properties" ]]; then
    #         echo "Error: Empty trigger definition in file: $filename"
    #         continue  # Skip to the next iteration
    #       fi

    #       echo "Deploying trigger $trigger_name from $filename"

    #       # Create ADF trigger using az command
    #       az datafactory trigger create \
    #         --factory-name "sally-tie-out-reporting-poc" \
    #         --resource-group "cw-mobile-rg" \
    #           --name "$trigger_name" \
    #           --properties "$trigger_properties" \
    #           --verbose

    #       echo "Created trigger: $trigger_name"
    #     done

      # Loop through trigger JSON files
    # - name: Loop through Trigger JSON files
    #   run: |
    #     for filename in ./trigger/*.json; do
    #       trigger_name="${filename##*/}"
    #       trigger_name="${trigger_name%.*}"  # Extract name from filename

    #       # Read trigger JSON content and format it as a JSON string
    #       trigger_properties=$(jq -c '.properties' "$filename")
          
    #       # Check if trigger definition is empty
    #       if [[ -z "$trigger_properties" ]]; then
    #         echo "Error: Empty trigger definition in file: $filename"
    #         continue  # Skip to the next iteration
    #       fi

    #       echo "Deploying trigger $trigger_name from $filename"

    #       # Create ADF trigger using az command
        #   az datafactory trigger create \
        #     --factory-name "sally-tie-out-reporting-poc" \
        #     --resource-group "cw-mobile-rg" \
        #       --name "$trigger_name" \
        #       --properties "$trigger_properties" \
        #       --verbose

        #   echo "Created trigger: $trigger_name"
        # done